from typing import Any, Generator
from dat_core.connectors.sources.stream import Stream
from dat_core.pydantic_models import DatCatalog, DatDocumentStream, DatMessage, StreamState
from dat_core.doc_splitters.factory import doc_splitter_factory, DocLoaderType, TextSplitterType
from verified_sources.<module_name>.specs import <actor_name>Specification

class <actor_name>Stream0(Stream):
    """
    <module_name>Stream0 class for crawling and processing URLs.

    Attributes:
        _name (str): The name of the <module_name>Stream0 stream ('url_crawler').

    Methods:
        __init__: Initializes a new <module_name>Stream0 object.
        read_records: Reads records from the configured stream and yields DatMessage objects.
    """

    _name = '<module_name>_stream_0'

    def __init__(self, config: <actor_name>Specification) -> None:
        """
        Initializes a new <module_name>Stream0 object.

        Parameters:
            config (<actor_name>Specification): The configuration object for URL crawling.
        """
        self._config = config
    
    def read_records(self, 
        catalog: DatCatalog,
        configured_stream: DatDocumentStream,
        cursor_value: Any = None
        ) -> Generator[DatMessage, Any, Any]:
        """
        Reads records from the configured stream and yields DatMessage objects.

        Parameters:
            catalog (DatCatalog): The DatCatalog object.
            configured_stream (DatDocumentStream): The configured DatDocumentStream object.
            cursor_value (Any, optional): The cursor value (default: None).

        Yields:
            Generator[DatMessage, Any, Any]: A generator yielding DatMessage objects.
        """